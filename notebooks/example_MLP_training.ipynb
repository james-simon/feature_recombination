{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2ezVCk_fFJ6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "plt.rc(\"figure\", dpi=100, facecolor=(1, 1, 1))\n",
        "plt.rc(\"font\", family='stixgeneral', size=14)\n",
        "plt.rc(\"axes\", facecolor=(1, .99, .95), titlesize=18)\n",
        "plt.rc(\"mathtext\", fontset='cm')\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "from kernels import ReluNTK\n",
        "from feature_decomp import Monomial, generate_hea_monomials\n",
        "from utils import ensure_torch\n",
        "from utils import derive_seed, seed_everything\n",
        "from mlps import MLP, train_network\n",
        "from tools import trial_count_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcKKX1RVV3qn"
      },
      "outputs": [],
      "source": [
        "EXPT_NAME = \"mlp-learning-curves\"\n",
        "N_TRAIN = 4_000\n",
        "N_TEST = 10_000\n",
        "N_TOT = N_TEST+N_TRAIN\n",
        "NS = np.logspace(1, 3, 20, dtype=int)\n",
        "DATASET = \"synthetic\"\n",
        "kerneltype = ReluNTK\n",
        "TARGET_FUNCTION_TYPE = \"monomial\" # just powerlaw for now\n",
        "ONLYTHRESHOLDS = True # if True, only record last loss instead of full curve\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# MLP HPs\n",
        "LR = 1e-2 #   base 1e-2\n",
        "DEPTH = 3 #   base 3\n",
        "WIDTH = 1024 #base 1024\n",
        "GAMMA = 1 #   base 1\n",
        "NS=np.array([1024]) # base 1024\n",
        "\n",
        "# Training HPs\n",
        "ONLINE = True\n",
        "LOSS_CHECKPOINTS = (0.1, 1e-12) #needs a len atm\n",
        "MAX_ITER = int(1e20)\n",
        "EMA_SMOOTHER = 0.9\n",
        "DETERMINSITIC = True\n",
        "trial_counts = np.array([trial_count_fn(n) for n in NS], dtype=int)\n",
        "# max_trials   = int(trial_counts.max())\n",
        "if ONLINE:\n",
        "    NS=np.array([1024])\n",
        "    trial_counts = np.ones_like(NS)*3\n",
        "    LOSS_CHECKPOINTS = (0.15, 0.1)\n",
        "\n",
        "global_config = dict(DEPTH=DEPTH, WIDTH=WIDTH, LR=LR, GAMMA=GAMMA,\n",
        "    EMA_SMOOTHER=EMA_SMOOTHER, MAX_ITER=MAX_ITER,\n",
        "    LOSS_CHECKPOINTS=LOSS_CHECKPOINTS, N_TEST=N_TEST,\n",
        "    SEED=SEED, ONLYTHRESHOLDS=ONLYTHRESHOLDS,\n",
        ")\n",
        "\n",
        "# Dataset HPs\n",
        "# Note: not all of these are used for all datasets\n",
        "datasethps = {\"normalized\": True,\n",
        "              \"cutoff_mode\": 20_000,\n",
        "              \"d\": 200,\n",
        "              \"offset\": 6,\n",
        "              \"alpha\": 1.7, #1.14~ is cifar\n",
        "              \"noise_size\": 1,\n",
        "              \"yoffset\": 1.2,\n",
        "              \"beta\": 1.2,\n",
        "              \"classes\": None,\n",
        "              \"binarize\": False,\n",
        "              \"weight_variance\": 1,\n",
        "              \"bias_variance\": 1,\n",
        "              \"kmax\":6,\n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OIIOu2Gtum0"
      },
      "outputs": [],
      "source": [
        "def run_trial(job, global_config, bfn_config=None, jobid=None):\n",
        "    base_seed = global_config.get(\"SEED\", None)\n",
        "    job_seed  = derive_seed(base_seed, jobid)\n",
        "    GEN, RNG = seed_everything(job_seed, jobid)\n",
        "\n",
        "    torch.set_num_threads(1)  # avoid CPU contention when many procs\n",
        "\n",
        "    if TARGET_FUNCTION_TYPE == \"monomial\":\n",
        "        from data import polynomial_batch_fn\n",
        "        batch_function = lambda target_monomial, n, X, y: polynomial_batch_fn(**bfn_config, monomials=target_monomial, bsz=n, gen=GEN, X=X, y=y)\n",
        "    target, n, trial = job\n",
        "    X_te, y_te = batch_function(target, global_config[\"N_TEST\"], X=None, y=None)(0)\n",
        "\n",
        "    X_tr, y_tr = batch_function(target, n, X=None, y=None)(trial) if not ONLINE else None, None\n",
        "\n",
        "    bfn = batch_function(target, n, X=X_tr, y=y_tr)\n",
        "\n",
        "    model = MLP(d_in=global_config[\"DIM\"], depth=global_config[\"DEPTH\"],\n",
        "                d_out=1, width=global_config[\"WIDTH\"]).to(device)\n",
        "\n",
        "    outdict = train_network(\n",
        "        model=model,\n",
        "        batch_function=bfn,\n",
        "        lr=global_config[\"LR\"],\n",
        "        max_iter=global_config[\"MAX_ITER\"],\n",
        "        loss_checkpoints=global_config[\"LOSS_CHECKPOINTS\"],\n",
        "        gamma=global_config[\"GAMMA\"],\n",
        "        ema_smoother=global_config[\"EMA_SMOOTHER\"],\n",
        "        only_thresholds=global_config[\"ONLYTHRESHOLDS\"],\n",
        "        X_tr=X_tr, y_tr=y_tr,\n",
        "        X_te=X_te, y_te=y_te,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    timekeys = outdict[\"timekeys\"]\n",
        "    train_losses = outdict[\"train_losses\"]\n",
        "    test_losses = outdict[\"test_losses\"]\n",
        "\n",
        "    # Cleanup GPU memory\n",
        "    del outdict, model, X_tr, y_tr, X_te, y_te\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return (n, str(target), int(trial), train_losses, test_losses, timekeys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nglK77yiKcuO",
        "outputId": "e921bade-7d46-43f8-b3db-4f5af646d201"
      },
      "outputs": [],
      "source": [
        "def select_indices_with_geometric_decay(values, ratio=.9):\n",
        "\n",
        "  # assert that values is (a) positive and (b) already sorted\n",
        "  assert np.all(values > 0)\n",
        "  assert np.all(np.diff(values) <= 0)\n",
        "\n",
        "  selected_indices = []\n",
        "\n",
        "  cur_eigval_thresh = values[0] + 1\n",
        "  ratio = .9\n",
        "\n",
        "  for i in range(len(hea_eigvals)):\n",
        "    if values[i] < cur_eigval_thresh:\n",
        "      selected_indices.append(i)\n",
        "      cur_eigval_thresh = values[i] * ratio\n",
        "\n",
        "  return selected_indices\n",
        "\n",
        "from data import get_powerlaw\n",
        "data_eigvals = get_powerlaw(P=datasethps['d'], exp=datasethps['alpha'], offset=datasethps['offset'], normalize=True) #aka data_eigvals\n",
        "level_coeff_fn = ReluNTK.get_level_coeff_fn(data_eigvals=data_eigvals, bias_variance=1, weight_variance=1)\n",
        "hea_eigvals, monomials = generate_hea_monomials(data_eigvals, datasethps['cutoff_mode'], level_coeff_fn, kmax=6) #don't touch kmax, not going above order 6\n",
        "\n",
        "data_indices_of_interest = [0, 1, 2, 3, 5, 10, 20, 40, 60, 100, 150]\n",
        "gammas_of_interest = data_eigvals.cpu().numpy()[data_indices_of_interest]\n",
        "hea_eigvals, monomials = generate_hea_monomials(gammas_of_interest, datasethps['cutoff_mode'], level_coeff_fn, kmax=4)\n",
        "\n",
        "selected_indices = select_indices_with_geometric_decay(hea_eigvals, .9)\n",
        "hea_eigenval_cutoff = 1e-6\n",
        "selected_indices = [i for i in selected_indices if hea_eigvals[i] > hea_eigenval_cutoff]\n",
        "\n",
        "selected_hea_eigvals = hea_eigvals[selected_indices]\n",
        "selected_monomials = [monomials[i] for i in selected_indices]\n",
        "\n",
        "# f\"selected {len(selected_indices)} HEA eigenmodes.\"\n",
        "monomials_as_dicts = [monomial.basis() for monomial in monomials]\n",
        "mapped_monomials_as_dicts = []\n",
        "for monomial_dict in monomials_as_dicts:\n",
        "    mapped_dict = {}\n",
        "    for key, value in monomial_dict.items():\n",
        "        mapped_key = data_indices_of_interest[key]\n",
        "        mapped_dict[mapped_key] = value\n",
        "    mapped_monomials_as_dicts.append(mapped_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "U4MkgMtVVukz",
        "outputId": "573bb023-b01c-4aad-93eb-5a9af4662ff1"
      },
      "outputs": [],
      "source": [
        "## --- Grab targets and such ---\n",
        "if DATASET == \"synthetic\":\n",
        "    from notebook_fns import get_synthetic_dataset\n",
        "\n",
        "    X_full, _, H, monomials, hea_eigvals, _, data_eigvals = get_synthetic_dataset(**datasethps, N=N_TOT, kerneltype=kerneltype,\n",
        "                                                                                        gen=torch.Generator(device='cuda').manual_seed(SEED))\n",
        "\n",
        "elif DATASET == \"cifar10\":\n",
        "    from imdata import ImageData\n",
        "    PIXEL_NORMALIZED =  False\n",
        "    classes = datasethps['classes']\n",
        "    normalized = datasethps['normalized']\n",
        "\n",
        "    if classes is not None:\n",
        "        imdata = ImageData('cifar10', \"../data\", classes=classes, onehot=len(classes)!=2, format=\"N\")\n",
        "    else:\n",
        "        imdata = ImageData('cifar10', \"../data\", classes=classes, onehot=False, format=\"N\")\n",
        "    X_train, y_train = imdata.get_dataset(N_TRAIN, **datasethps, get='train',\n",
        "                                        centered=True, normalize=PIXEL_NORMALIZED)\n",
        "    X_test, y_test = imdata.get_dataset(N_TEST, **datasethps, get='test',\n",
        "                                        centered=True, normalize=PIXEL_NORMALIZED)\n",
        "    X_train, y_train, X_test, y_test = map(ensure_torch, (X_train, y_train, X_test, y_test))\n",
        "    y_train = y_train.squeeze()\n",
        "    y_test = y_test.squeeze()\n",
        "    X_train, y_train, X_test, y_test = [t/torch.linalg.norm(t) for t in (X_train, y_train, X_test, y_test)] if normalized else (X_train, y_train, X_test, y_test)\n",
        "    if normalized:\n",
        "        X_train *= N_TRAIN**(0.5); X_test *= N_TEST**(0.5)\n",
        "        y_train *= N_TRAIN**(0.5); y_test *= N_TEST**(0.5)\n",
        "    X_full = torch.cat((X_train, X_test), dim=0)\n",
        "    y_full = torch.cat((y_train, y_test), dim=0)\n",
        "    data_eigvals = torch.linalg.svdvals(X_full)**2\n",
        "    data_eigvals /= data_eigvals.sum()\n",
        "\n",
        "\n",
        "U, lambdas, Vt = torch.linalg.svd(X_full, full_matrices=False)\n",
        "dim = X_full.shape[1]\n",
        "\n",
        "## --- Target function defs ---\n",
        "if TARGET_FUNCTION_TYPE == \"monomial\":\n",
        "    target_monomials = [Monomial(mmd) for mmd in mapped_monomials_as_dicts]\n",
        "    targets = target_monomials\n",
        "    bfn_config = dict(lambdas=lambdas, Vt=Vt, data_eigvals=data_eigvals, N=N_TOT)\n",
        "\n",
        "global_config.update(dict(DIM=dim))\n",
        "\n",
        "jobs = [(target, n, trial)\n",
        "        for target in targets\n",
        "        for nidx, n in enumerate(NS)\n",
        "        for trial in range(int(trial_counts[nidx]))]\n",
        "\n",
        "total = len(jobs)\n",
        "done = 0\n",
        "print(f\"Training base case\")\n",
        "with tqdm(total=total, desc=\"Runs\", dynamic_ncols=True) as pbar:\n",
        "    while done < total:\n",
        "        job = jobs[done]\n",
        "        target = job[0]\n",
        "        n, tstr, trial, train_losses, test_losses, timekeys = run_trial(job, global_config, bfn_config, done)\n",
        "        if not(ONLYTHRESHOLDS):\n",
        "            train_losses = train_losses[-1]\n",
        "            test_losses = test_losses[-1]\n",
        "        print(\"\")\n",
        "        pbar.set_postfix_str(\n",
        "        f\"train {train_losses:.3g} | test {test_losses:.3g} | timekey {timekeys} | n={n} | target={tstr} | trial={trial}\",\n",
        "        refresh=False)\n",
        "\n",
        "        done += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TbksFx5s75aI"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
